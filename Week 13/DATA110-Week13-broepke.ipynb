{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5491ce0b",
   "metadata": {},
   "source": [
    "# Week 13 Assignment: Topic Modeling\n",
    "\n",
    "**DATA110**  \n",
    "*Brian Roepke*  \n",
    "\n",
    "Using the same women's clothing dataset from Midterm #2, perform Topic Modeling using LDA using either packages: Gensim  or sklearn on the reviews text.  \n",
    "\n",
    "\n",
    "Given that there are 6 departments, you can use  6 topics.  Bonus if you apply coherence computations against multiple models for model selection, in order to determine the optimal number of topics.\n",
    "\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html#sphx-glr-auto-examples-core-run-core-concepts-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#from textblob import TextBlob\n",
    "#from textblob import Word\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import nmf\n",
    "from gensim.models import lsimodel\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# NLTK Imports and Downloads\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ClothingReviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecf7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Department Name', 'Class Name', 'Review Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the NA values with 0\n",
    "df['Title'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28463af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Title'] + ' ' + df['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Title', 'Review Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ac5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column 'text_len' that counts the length for the derived field\n",
    "df['text_len'] = df.apply(lambda row: len(row['Text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_before = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "len_after = df.shape[0]\n",
    "\n",
    "print(\"Before =\", len_before)\n",
    "# drop duplicates\n",
    "print(\"After =\", len_after)\n",
    "print('')\n",
    "print(\"Total Removed =\", len_before - len_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlen = df['Text'].str.split().map(lambda x: len(x))\n",
    "wordlen.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa832a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ad506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(text, stem=\"None\"):\n",
    "    \n",
    "    final_string = \"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "    useless_words = useless_words + ['.', ',', '!', \"'\"]\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "    \n",
    "    if stem == 'Stem':\n",
    "        stemmer = PorterStemmer() \n",
    "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "    elif stem == 'Lem':\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "    else:\n",
    "        text_stemmed = text_filtered\n",
    "    \n",
    "    for word in text_stemmed:\n",
    "        final_string += word + \" \"\n",
    "    \n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Processed'] = df['Text'].apply(lambda x: process_string(x, stem='Lem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aec9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Processed'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9311a44",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d472014",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_docs = df['Text_Processed'].to_list()\n",
    "\n",
    "# first 5 docs\n",
    "clean_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = \"\".join(clean_docs)\n",
    "word_tokens = word_tokenize(texts)\n",
    "#fdist.most_common(50)\n",
    "\n",
    "plt.figure(figsize=(15, 5)) \n",
    "fdist = FreqDist(word_tokens)\n",
    "fdist.plot(50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91982c",
   "metadata": {},
   "source": [
    "# Determine the Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa7e65",
   "metadata": {},
   "source": [
    "## Elbow Method\n",
    "\n",
    "To select the best number of clusters, we'll use the Elbow method.  Per [Wikipedia](https://en.wikipedia.org/wiki/Elbow_method_(clustering))\n",
    "\n",
    "> *In cluster analysis, the elbow method is a heuristic used in determining the number of clusters in a data set. The method consists of plotting the explained variation as a function of the number of clusters, and picking the elbow of the curve as the number of clusters to use. The same method can be used to choose the number of parameters in other data-driven models, such as the number of principal components to describe a data set.*\n",
    "\n",
    "[Tutorial: How to determine the optimal number of clusters for k-means clustering](https://blog.cambridgespark.com/how-to-determine-the-optimal-number-of-clusters-for-k-means-clustering-14f27070048f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization of features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(clean_docs)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a434058",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=K, y=Sum_of_squared_distances)\n",
    "ax.lines[0].set_linestyle(\"--\")\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8118461",
   "metadata": {},
   "source": [
    "**Conclusion:** Based on this method, the appropriate number of clusters is not totally clear. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c851a9c",
   "metadata": {},
   "source": [
    "## Silhouette Score\n",
    "\n",
    "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html?highlight=silhouette_score#sklearn.metrics.silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette_score(X, k):\n",
    "    for n_clusters in range(2, k):\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        y = clusterer.fit_predict(X)\n",
    "\n",
    "        message = \"For n_clusters = {} The average silhouette_score is: {}\"\n",
    "        print(message.format(n_clusters, silhouette_score(X, y)))\n",
    "        \n",
    "get_silhouette_score(X, 10)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be598c6c",
   "metadata": {},
   "source": [
    "**Conclusion:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012e9cb",
   "metadata": {},
   "source": [
    "# Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 6\n",
    "kmeans = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "\n",
    "for i in range(true_k):\n",
    "    terms_list = []\n",
    "    \n",
    "    for ind in order_centroids[i, :15]:  \n",
    "        terms_list.append(terms[ind])\n",
    "    \n",
    "    results_dict[f'Custer{i}'] = terms_list\n",
    "    \n",
    "df_clusters = pd.DataFrame.from_dict(results_dict)\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the data labels back to the dataframe\n",
    "df['clusters'] = kmeans.labels_\n",
    "\n",
    "df.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs = ['This dress is gorgeous and I love it and would gladly reccomend it to all of my friends.',\n",
    "            'This skirt has really horible quality and I hate it!',\n",
    "            'A super cute top with the perfect fit.',\n",
    "            'The most gorgeous pair of jeans I have seen.',\n",
    "            'this item is too little and tight.']\n",
    "\n",
    "pred = kmeans.predict(vectorizer.transform(new_docs))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a2a6e7",
   "metadata": {},
   "source": [
    "# GenSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01558450",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_docs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70afc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = [word_tokenize(word) for word in clean_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8808e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary from the corpus\n",
    "dictionary = gensim.corpora.Dictionary(tokenized_docs)\n",
    "print(dictionary)\n",
    "\n",
    "# Term Document Frequency \n",
    "# convert our entire corpus to a list of vectors:\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "# View the first doc\n",
    "print(bow_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eec905",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = bow_corpus[1]\n",
    "for i in range(len(doc)):\n",
    "    print (f\"Word {doc[i][0]} ({dictionary[doc[i][0]]}) appears {doc[i][1]} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e733b997",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ab5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 6\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=NUM_TOPICS, \n",
    "                                           random_state=42,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "### View the topics in LDA model\n",
    "topics = lda_model.print_topics()\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = 'This dress is gorgeous and I love it and would gladly reccomend it to all of my friends.'\n",
    "new_doc = process_string(new_doc)\n",
    "new_doc = word_tokenize(new_doc)\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "\n",
    "print(new_doc_bow)\n",
    "print(lda_model.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381c4d8",
   "metadata": {},
   "source": [
    "# Model Perplexity and Coherence Score\n",
    "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scoring (model, corpus, text, dictionary, perplex=False):\n",
    "\n",
    "    # Compute Perplexity\n",
    "    # a measure of how good the model is. lower the better.\n",
    "    if perplex:\n",
    "        print('\\nPerplexity: ', model.log_perplexity(corpus))  \n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model = CoherenceModel(model=model, \n",
    "                                         texts=text, \n",
    "                                         dictionary=dictionary, \n",
    "                                         coherence='c_v')\n",
    "    \n",
    "    coherence_lda = coherence_model.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scoring(lda_model, bow_corpus, tokenized_docs, dictionary, perplex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = gensim.models.nmf.Nmf(corpus=bow_corpus, \n",
    "                      num_topics=NUM_TOPICS, \n",
    "                      id2word=dictionary, \n",
    "                      chunksize=2000, \n",
    "                      passes=10, \n",
    "                      random_state=42)\n",
    "\n",
    "model_scoring(nmf_model, bow_corpus, tokenized_docs, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18fa5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = gensim.models.lsimodel.LsiModel(corpus=bow_corpus, \n",
    "                                num_topics=NUM_TOPICS, \n",
    "                                id2word=dictionary)\n",
    "\n",
    "model_scoring(lsi, bow_corpus, tokenized_docs, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eceac8",
   "metadata": {},
   "source": [
    "## Topic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaaefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# feed the LDA model into the pyLDAvis instance\n",
    "lda_viz = gensimvis.prepare(lda_model, bow_corpus, dictionary, sort_topics=False)\n",
    "\n",
    "pyLDAvis.display(lda_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1123f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
