{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handy-webcam",
   "metadata": {},
   "source": [
    "# Week 9 Assignment: NLP Text classification\n",
    "\n",
    "Create a NLP text classifier to predict whether a text message is spam. \n",
    "\n",
    "1) Load the dataset which includes 2 fields: (text and label) where label  indicates whether the message is “spam” or \"not spam\"  (eg: ham).\n",
    "\n",
    "2) Perform basic EDA\n",
    "\n",
    "3) Perform preprocessing of text (eg: lower-case, tokenization, removal of stop words, stemming/lemmatization, etc. as needed)\n",
    "\n",
    "4) Vectorize Text (eg: BoW, TF-IDF, etc)\n",
    "\n",
    "5) Create a model, using at least 2 different ML algorithms\n",
    "    \n",
    " * Split the data into training and testing set\n",
    " * Train the model on training, then predict and assess performance on test\n",
    " * predict custom messages (eg: your own custom message, at least 3) to evaluate how well your model categorized it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "refined-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import itertools\n",
    "import random\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics \n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radical-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wicked-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "express-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy without any transformations for us with Sklearn\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "israeli-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a length of text column before the cleaning\n",
    "df['length'] = df.apply(lambda row: len(row.text), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-international",
   "metadata": {},
   "source": [
    "## Data Cleaning & EDA\n",
    "\n",
    "Perform the following transfermations\n",
    "\n",
    "1. Replace the output variables of `ham` and `spam` with `1` and `0`\n",
    "1. Covert all text to lowercase\n",
    "1. Tokenize the words\n",
    "1. Remove stop words & puncutation\n",
    "1. Remove accented characters\n",
    "1. Stemm the words\n",
    "1. Add a column for the count of words after text is tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decent-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the text based labels with 1 and 0\n",
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n",
    "# Convert all to lowercase\n",
    "df['text'] = df.text.map(lambda x: x.lower())\n",
    "# Convert all to lowercase\n",
    "df['text'] = df.text.map(lambda x: unidecode.unidecode(x))\n",
    "# Tokenize the words\n",
    "df['text'] = df['text'].apply(word_tokenize)\n",
    "# Remove stopword\n",
    "useless_words = stopwords.words(\"english\") + list(string.punctuation)\n",
    "useless_words = useless_words + [\"...\", \"..\", \"''\", \"'s\"]\n",
    "df['text'] = df['text'].apply(lambda x: [y for y in x if not y in useless_words])\n",
    "# Stem the tokenized words\n",
    "stemmer = PorterStemmer() \n",
    "df['text'] = df['text'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "overhead-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a length of text column\n",
    "df['tok_length'] = df.apply(lambda row: len(row.text), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minor-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tok_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>111</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>155</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  length  \\\n",
       "0      0  [go, jurong, point, crazi, avail, bugi, n, gre...     111   \n",
       "1      0                       [ok, lar, joke, wif, u, oni]      29   \n",
       "2      1  [free, entri, 2, wkli, comp, win, fa, cup, fin...     155   \n",
       "3      0      [u, dun, say, earli, hor, u, c, alreadi, say]      49   \n",
       "4      0  [nah, n't, think, goe, usf, live, around, though]      61   \n",
       "\n",
       "   tok_length  \n",
       "0          16  \n",
       "1           6  \n",
       "2          25  \n",
       "3           9  \n",
       "4           8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stock-tourist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tok_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u., u, aps750, po...</td>\n",
       "      <td>161</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>[i_, b, go, esplanad, fr, home]</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>[piti, mood, suggest]</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>[guy, bitch, act, like, 'd, interest, buy, som...</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  length  \\\n",
       "5567      1  [2nd, time, tri, 2, contact, u., u, aps750, po...     161   \n",
       "5568      0                    [i_, b, go, esplanad, fr, home]      37   \n",
       "5569      0                              [piti, mood, suggest]      57   \n",
       "5570      0  [guy, bitch, act, like, 'd, interest, buy, som...     125   \n",
       "5571      0                                 [rofl, true, name]      26   \n",
       "\n",
       "      tok_length  \n",
       "5567          20  \n",
       "5568           6  \n",
       "5569           3  \n",
       "5570          14  \n",
       "5571           3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "western-warrant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   label       5572 non-null   int64 \n",
      " 1   text        5572 non-null   object\n",
      " 2   length      5572 non-null   int64 \n",
      " 3   tok_length  5572 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 174.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "middle-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>tok_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572.00</td>\n",
       "      <td>5572.00</td>\n",
       "      <td>5572.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.13</td>\n",
       "      <td>80.12</td>\n",
       "      <td>9.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.34</td>\n",
       "      <td>59.69</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>910.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label   length  tok_length\n",
       "count  5572.00  5572.00     5572.00\n",
       "mean      0.13    80.12        9.59\n",
       "std       0.34    59.69        7.15\n",
       "min       0.00     2.00        0.00\n",
       "25%       0.00    36.00        4.00\n",
       "50%       0.00    61.00        7.00\n",
       "75%       0.00   121.00       14.00\n",
       "max       1.00   910.00       80.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gentle-harmony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df['label'], palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df, x='length', kde=True, palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df, x='tok_length', kde=True, palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.boxplot(data=df[['length']], palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.boxplot(data=df[['tok_length']], palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only Ham\n",
    "df_ham = df[df['label'] == 0]\n",
    "# Extract only SPAM\n",
    "df_spam = df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_stats_ham = []\n",
    "for i in df_ham['text']:\n",
    "    freq_stats_ham = freq_stats_ham + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_ham = FreqDist(freq_stats_ham)\n",
    "fdist_ham.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fdist_ham.plot(20, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_stats_spam = []\n",
    "for i in df_spam['text']:\n",
    "    freq_stats_spam = freq_stats_spam + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_spam = FreqDist(freq_stats_spam)\n",
    "fdist_spam.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fdist_spam.plot(20, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter_ham = Counter(freq_stats_ham)\n",
    "sorted_word_counts_ham = sorted(list(word_counter_ham.values()), reverse=True) \n",
    "\n",
    "plt.loglog(sorted_word_counts_ham)\n",
    "plt.ylabel('Freq')\n",
    "plt.xlabel('Word Rank');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter_spam = Counter(freq_stats_spam)\n",
    "sorted_word_counts_spam = sorted(list(word_counter_spam.values()), reverse=True) \n",
    "\n",
    "plt.loglog(sorted_word_counts_spam)\n",
    "plt.ylabel('Freq')\n",
    "plt.xlabel('Word Rank');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the order of the columns and remove anything we don't need post analysis.\n",
    "df = df[['text', 'label']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-miracle",
   "metadata": {},
   "source": [
    "# NLTK Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a bad of words...\n",
    "def build_bag_of_words_features(words):\n",
    "    return {word:1 for word in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds a list of positive reviews words/features with stop words and punction removed\n",
    "ham_features = [(build_bag_of_words_features(x), 'ham')\n",
    "               for x in df_ham['text']]\n",
    "\n",
    "print(ham_features[0])\n",
    "print(ham_features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ham_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds a list of negative reviews words/features with stop words and punction removed\n",
    "spam_features = [(build_bag_of_words_features(x), 'spam')\n",
    "                 for x in df_spam['text']]\n",
    "\n",
    "print(spam_features[0])\n",
    "print(spam_features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_spam = 500\n",
    "split_ham = 500\n",
    "\n",
    "# split, train, test \n",
    "train = ham_features[:split_ham] + spam_features[:split_spam]\n",
    "random.shuffle(train)\n",
    "\n",
    "sent_classifier = NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num features for train: ', len(train))\n",
    "\n",
    "nltk.classify.util.accuracy(sent_classifier, train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining for test\n",
    "test = ham_features[split_ham:] + spam_features[split_spam:]\n",
    "\n",
    "print('num features for test: ', len(test))\n",
    "\n",
    "nltk.classify.util.accuracy(sent_classifier, test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_classifier.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-school",
   "metadata": {},
   "source": [
    "### Test with Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training vocabulary\n",
    "train_vocab = set()\n",
    "\n",
    "for t in train:\n",
    "    vocabDict = t[0]\n",
    "    for key in vocabDict.keys():\n",
    "      train_vocab.add(key)\n",
    "len(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "docs=[\"txt us at 8787 for a free trip to hawaii!\", \n",
    "    \"I'm looking forward to when my day is over\",\n",
    "    \"Nah I don't think he goes to usf\",\n",
    "    \"for a free week of mobile service award\"]\n",
    "\n",
    "for doc in docs:\n",
    "     t_features = {word: (word in word_tokenize(doc.lower())) for word in train_vocab}\n",
    "     print(doc,\" : \", sent_classifier.classify(t_features)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-subsection",
   "metadata": {},
   "source": [
    "# Scikit Learn Naive Bayes Classification\n",
    "\n",
    "The following section will look to classify the data based on Scikit-Learn's `NaiveBayesClassification`, and specifically the `MultinomialNB` algorithm.  A number of options through different versions of the same process\n",
    "\n",
    "1. **Four total passes**\n",
    "    - The first two will use an imbalanced dataset\n",
    "    - The second two will use a balanced training set\n",
    "1. **For each of the two passes, different word vectorization will be used.**\n",
    "    - `CountVectorizer` which uses a sparse matrix of token counts per document\n",
    "    - `TfidfVectorizer` Tf-idf instead of the token counts, scales down the impact of tokens that occur very frequently in a given corpus and that are hence less informative than features that occur in a small fraction of the training corpus.\n",
    "1. **Hyper Parameter Tuning**\n",
    "    - Each of the passes will use a Grid Search Cross Validation to pick the best performing `alpha` setting.  This is tuned per training data set, and per word vectorization model from step 2.\n",
    "\n",
    "After everything is run, we can see which model performed the best.  The metric for determining the best model is `percision` primarily, since it will measure how precise/accurate the model is out of those predicted positive, how many of them are actual positive.\n",
    "\n",
    ">Precision is a good measure to determine, when the costs of False Positive is high. For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model[3].\n",
    "\n",
    "**Note:** Different than the NLTK version above, we will not do any special pre-processing but rather let `scikit-learn` do stop word removal and accent removal.  Because of this, we'll start with the raw imported CSV.\n",
    "\n",
    "**References:**  \n",
    " 1. [Detecting Fake News with Scikit-Learn](https://www.datacamp.com/community/tutorials/scikit-learn-fake-news)  \n",
    " 1. [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18)\n",
    " 1. [Accuracy, Precision, Recall or F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "# Set `y` \n",
    "y = df.label\n",
    "X = df['text']\n",
    "\n",
    "# Drop the `label` column\n",
    "df.drop(\"label\", axis=1)\n",
    "\n",
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-basis",
   "metadata": {},
   "source": [
    "## Models on Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english', strip_accents='unicode')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7, strip_accents='unicode') \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names of `tfidf_vectorizer` \n",
    "print(tfidf_vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# Get the feature names of `count_vectorizer` \n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-bronze",
   "metadata": {},
   "source": [
    "**Note:** The empty `set` denotes that the features (columns) are identical between the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(X, y):\n",
    "    vals = np.linspace(.0001, 2, 100)\n",
    "\n",
    "    parameters = {'alpha':vals}\n",
    "    model = MultinomialNB()\n",
    "    clf = GridSearchCV(model, parameters)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # extract the best alpha score\n",
    "    return clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph_dict = get_alpha(count_train, y_train)\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(count_train, y_train)\n",
    "y_pred = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph_dict = get_alpha(tfidf_train, y_train)\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(tfidf_train, y_train)\n",
    "y_pred = clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-brunswick",
   "metadata": {},
   "source": [
    "## Oversample the Minority Class\n",
    "Oversampling can be defined as adding more copies of the minority class. Oversampling can be a good choice when you don’t have a ton of data to work with.  \n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html?highlight=resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "ham = X[X.label == 'ham']\n",
    "spam = X[X.label == 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "spam_upsampled = resample(spam,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(ham), # match number in majority class\n",
    "                          random_state=27) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([ham, spam_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new class counts\n",
    "upsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-clock",
   "metadata": {},
   "source": [
    "**Note:** Now we can see that the number of `spam` and `ham` entries are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-america",
   "metadata": {},
   "source": [
    "## Post Oversampling Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced dataset\n",
    "y_train = upsampled.label\n",
    "X_train = upsampled.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english', strip_accents='unicode')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode') \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph_dict = get_alpha(count_train, y_train)\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(count_train, y_train)\n",
    "y_pred = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph_dict = get_alpha(tfidf_train, y_train)\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(tfidf_train, y_train)\n",
    "y_pred = clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-technician",
   "metadata": {},
   "source": [
    "## Test with Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"txt us at 8787 for a free trip to hawaii!\", \n",
    "     \"I'm looking forward to when my day is over\",\n",
    "     \"Nah I don't think he goes to usf\",\n",
    "     \"for a free week of mobile service\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    sample_trans = tfidf_vectorizer.transform([sample])\n",
    "    print(sample, \"=\", clf.predict(sample_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-migration",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-repeat",
   "metadata": {},
   "source": [
    "# Clustering with Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "X = df['text']\n",
    "\n",
    "# Drop the `label` column\n",
    "df.drop(\"label\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train k-means model\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=1000, n_init=1, random_state=999)\n",
    "model.fit(X)\n",
    "\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "print(\"\\nTop prediction:\")\n",
    "new_docs = [\"txt us at 8787 for a free trip to hawaii!\", \n",
    "     \"I'm looking forward to when my day is over\",\n",
    "     \"Nah I don't think he goes to usf\",\n",
    "     \"for a free week of mobile service\"]\n",
    "\n",
    "# prediction\n",
    "pred = model.predict(vectorizer.transform(new_docs))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-surge",
   "metadata": {},
   "source": [
    "**kMeans Notes:**  \n",
    "\n",
    "The kMeans clustering unsupervised algorithm with two clusters comes up with an approimation of a `spam` and a `ham` cluster.  feeding in the same items from our prior tests result in the same predictions.  `#1` and `#4` predicted as `spam`, and `#2` and `#3` as `ham`.\n",
    "\n",
    "While you wouldn't use an unsupervised method when you have actual labels, it demonstrates really well how clustering, an unsupervised method, can be used on text.  It is also very useful when you have some subject matter on the text, where we know there are generally `2` labels we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-chick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
