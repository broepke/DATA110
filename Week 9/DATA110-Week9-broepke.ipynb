{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vital-flash",
   "metadata": {},
   "source": [
    "# Week 9 Assignment: NLP Text classification\n",
    "\n",
    "Create a NLP text classifier to predict whether a text message is spam. \n",
    "\n",
    "1) Load the dataset which includes 2 fields: (text and label) where label  indicates whether the message is “spam” or \"not spam\"  (eg: ham).\n",
    "\n",
    "2) Perform basic EDA\n",
    "\n",
    "3) Perform preprocessing of text (eg: lower-case, tokenization, removal of stop words, stemming/lemmatization, etc. as needed)\n",
    "\n",
    "4) Vectorize Text (eg: BoW, TF-IDF, etc)\n",
    "\n",
    "5) Create a model, using at least 2 different ML algorithms\n",
    "    \n",
    " * Split the data into training and testing set\n",
    " * Train the model on training, then predict and assess performance on test\n",
    " * predict custom messages (eg: your own custom message, at least 3) to evaluate how well your model categorized it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dried-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import itertools\n",
    "import random\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics \n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annoying-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advised-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rubber-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy without any transformations for us with Sklearn\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "agricultural-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a length of text column before the cleaning\n",
    "df['length'] = df.apply(lambda row: len(row.text), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-opposition",
   "metadata": {},
   "source": [
    "## Data Cleaning & EDA\n",
    "\n",
    "Perform the following transfermations\n",
    "\n",
    "1. Replace the output variables of `ham` and `spam` with `1` and `0`\n",
    "1. Covert all text to lowercase\n",
    "1. Tokenize the words\n",
    "1. Remove stop words & puncutation\n",
    "1. Remove accented characters\n",
    "1. Stemm the words\n",
    "1. Add a column for the count of words after text is tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surprised-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the text based labels with 1 and 0\n",
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n",
    "# Convert all to lowercase\n",
    "df['text'] = df.text.apply(lambda x: x.lower())\n",
    "# Convert all to lowercase\n",
    "df['text'] = df.text.apply(lambda x: unidecode.unidecode(x))\n",
    "# Tokenize the words\n",
    "df['text'] = df.text.apply(word_tokenize)\n",
    "# Remove stopword\n",
    "useless_words = stopwords.words(\"english\") + list(string.punctuation)\n",
    "useless_words = useless_words + [\"...\", \"..\", \"''\", \"'s\"]\n",
    "df['text'] = df['text'].apply(lambda x: [y for y in x if not y in useless_words])\n",
    "# Stem the tokenized words\n",
    "stemmer = PorterStemmer() \n",
    "df['text'] = df['text'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mathematical-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a length of text column\n",
    "df['tok_length'] = df.apply(lambda row: len(row.text), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "trying-characterization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tok_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>111</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>155</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  length  \\\n",
       "0      0  [go, jurong, point, crazi, avail, bugi, n, gre...     111   \n",
       "1      0                       [ok, lar, joke, wif, u, oni]      29   \n",
       "2      1  [free, entri, 2, wkli, comp, win, fa, cup, fin...     155   \n",
       "3      0      [u, dun, say, earli, hor, u, c, alreadi, say]      49   \n",
       "4      0  [nah, n't, think, goe, usf, live, around, though]      61   \n",
       "\n",
       "   tok_length  \n",
       "0          16  \n",
       "1           6  \n",
       "2          25  \n",
       "3           9  \n",
       "4           8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mechanical-budapest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tok_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u., u, aps750, po...</td>\n",
       "      <td>161</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>[i_, b, go, esplanad, fr, home]</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>[piti, mood, suggest]</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>[guy, bitch, act, like, 'd, interest, buy, som...</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  length  \\\n",
       "5567      1  [2nd, time, tri, 2, contact, u., u, aps750, po...     161   \n",
       "5568      0                    [i_, b, go, esplanad, fr, home]      37   \n",
       "5569      0                              [piti, mood, suggest]      57   \n",
       "5570      0  [guy, bitch, act, like, 'd, interest, buy, som...     125   \n",
       "5571      0                                 [rofl, true, name]      26   \n",
       "\n",
       "      tok_length  \n",
       "5567          20  \n",
       "5568           6  \n",
       "5569           3  \n",
       "5570          14  \n",
       "5571           3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technological-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   label       5572 non-null   int64 \n",
      " 1   text        5572 non-null   object\n",
      " 2   length      5572 non-null   int64 \n",
      " 3   tok_length  5572 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 174.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "protected-variance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>tok_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572.00</td>\n",
       "      <td>5572.00</td>\n",
       "      <td>5572.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.13</td>\n",
       "      <td>80.12</td>\n",
       "      <td>9.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.34</td>\n",
       "      <td>59.69</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>910.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label   length  tok_length\n",
       "count  5572.00  5572.00     5572.00\n",
       "mean      0.13    80.12        9.59\n",
       "std       0.34    59.69        7.15\n",
       "min       0.00     2.00        0.00\n",
       "25%       0.00    36.00        4.00\n",
       "50%       0.00    61.00        7.00\n",
       "75%       0.00   121.00       14.00\n",
       "max       1.00   910.00       80.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-american",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    " - **Label**: This is just a binary label after changing from the categorical lables.  We'll count these in the next visualization.\n",
    " - **length**:  Character count for the text colum.  `Min` of `2` and `max` of `910`.  Mean is `80` characters meaning these are all bascially short messages not unlike Tweets.\n",
    " - **tok_length**:  Number of tokenized `words` in each message.  `Min` of `0` and `max` of `80`.  The mean number of words is approximatley `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['label'], palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-fraud",
   "metadata": {},
   "source": [
    "**Count of Ham/Spam**:  There are  a far greater portion of `ham` messages in the dataset compared to `spam`.  This is known as imbalanced data.  About `15.5%` are `spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df, x='length', kde=True, palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-annotation",
   "metadata": {},
   "source": [
    "**Notes**:  For the lenth (char count) we can see the right skewed data with most of the observations falling under `200` characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df, x='tok_length', kde=True, palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-bleeding",
   "metadata": {},
   "source": [
    "**Notes**:  For token lenth (number of words), most fall under `30` and a large proportion have less than `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.boxplot(data=df[['length']], palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-patrick",
   "metadata": {},
   "source": [
    "**Notes**:  Outliers can be observed outside of the upper quartile of approx `225`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.boxplot(data=df[['tok_length']], palette=\"tab20c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-bottle",
   "metadata": {},
   "source": [
    "**Notes**:  Outliers can be observed outside of the upper quartile of approx `225`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tok_length'] > 30].text.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-moment",
   "metadata": {},
   "source": [
    "**Outliers**: Given we are working with text data, there is nothing to suggest that these outliers (displayed above) are in error or will hurt our models.  They will stay in the datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only Ham\n",
    "df_ham = df[df['label'] == 0]\n",
    "# Extract only SPAM\n",
    "df_spam = df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_stats_ham = []\n",
    "for i in df_ham['text']:\n",
    "    freq_stats_ham = freq_stats_ham + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_ham = FreqDist(freq_stats_ham)\n",
    "fdist_ham.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-emission",
   "metadata": {},
   "source": [
    "**Frequent Ham Words:**  \n",
    "The top most frequently occuring words are `u`, `go`, `'m`, `get`, `n't`, `gt`, `lt`, and `2`. A lot of these seem like nonsensical words or slang.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fdist_ham.plot(20, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_text = nltk.Text(freq_stats_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ham_text.dispersion_plot(['u', 'go', \"'m\", 'get', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_stats_spam = []\n",
    "for i in df_spam['text']:\n",
    "    freq_stats_spam = freq_stats_spam + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_spam = FreqDist(freq_stats_spam)\n",
    "fdist_spam.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-roberts",
   "metadata": {},
   "source": [
    "**Frequent Spam Words:**  \n",
    "The top most frequently occuring words are `call`, `free`, `2`, `txt`, `u`, `ur`, `text`, and `mobile`.  A lot of these seem to be about free serives, gifts, prizes.  Certainly something that seems `spam` related. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fdist_spam.plot(20, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_text = nltk.Text(freq_stats_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "spam_text.dispersion_plot(['call', 'free', '2', 'text', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter_ham = Counter(freq_stats_ham)\n",
    "sorted_word_counts_ham = sorted(list(word_counter_ham.values()), reverse=True) \n",
    "\n",
    "plt.loglog(sorted_word_counts_ham)\n",
    "plt.ylabel('Freq')\n",
    "plt.xlabel('Word Rank');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter_spam = Counter(freq_stats_spam)\n",
    "sorted_word_counts_spam = sorted(list(word_counter_spam.values()), reverse=True) \n",
    "\n",
    "plt.loglog(sorted_word_counts_spam)\n",
    "plt.ylabel('Freq')\n",
    "plt.xlabel('Word Rank');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the order of the columns and remove anything we don't need post analysis.\n",
    "df = df[['text', 'label']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-clone",
   "metadata": {},
   "source": [
    "# NLTK Classifier\n",
    "\n",
    "We will use the NLTK `NaiveBayesClassifier` to build a classification model for our spam and ham.  The process for building the Bag of Words is simple with NLTK, building a tuple in the following format\n",
    "\n",
    "`({ \"word\": count, \"word2\": count}, class)`\n",
    "\n",
    "The following function creates this for each observation in the datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-growth",
   "metadata": {},
   "source": [
    "**Note**:  \n",
    "Before the data is oversampled, there are `623` spam entries in the training set and `124` in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-omega",
   "metadata": {},
   "source": [
    "## Oversample the Minority Class\n",
    "Oversampling can be defined as adding more copies of the minority class. Oversampling can be a good choice when you don’t have a ton of data to work with.  \n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class.\n",
    "\n",
    "https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html?highlight=resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "ham = X[X.label == 0]\n",
    "spam = X[X.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "spam_upsampled = resample(spam,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(ham), # match number in majority class\n",
    "                          random_state=27) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([ham, spam_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new class counts\n",
    "upsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-plate",
   "metadata": {},
   "source": [
    "**Note**:    \n",
    "Now that the data is oversampled, there is an equal number of `0` and `1` observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-scotland",
   "metadata": {},
   "source": [
    "### Build BoW for `Train` Data and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only Ham\n",
    "train_ham = upsampled[upsampled['label'] == 0]\n",
    "# Extract only SPAM\n",
    "train_spam = upsampled[upsampled['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a bad of words Function\n",
    "def build_bag_of_words_features(words):\n",
    "    return {word:1 for word in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds a list of positive reviews words/features with stop words and punction removed\n",
    "ham_train_features = [(build_bag_of_words_features(x), 'ham') for x in train_ham['text']]\n",
    "\n",
    "print(ham_train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds a list of positive reviews words/features with stop words and punction removed\n",
    "spam_train_features = [(build_bag_of_words_features(x), 'spam') for x in train_spam['text']]\n",
    "\n",
    "print(spam_train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ham_train_features + spam_train_features\n",
    "random.shuffle(train)\n",
    "\n",
    "sent_classifier = NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num features for train: ', len(train))\n",
    "\n",
    "nltk.classify.util.accuracy(sent_classifier, train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-cause",
   "metadata": {},
   "source": [
    "### Build BoW for `Test` Data and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "all_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only Ham\n",
    "test_ham = all_test[all_test['label'] == 0]\n",
    "# Extract only SPAM\n",
    "test_spam = all_test[all_test['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds a list of positive reviews words/features with stop words and punction removed\n",
    "ham_test_features = [(build_bag_of_words_features(x), 'ham') for x in test_ham['text']]\n",
    "\n",
    "print(ham_test_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds a list of positive reviews words/features with stop words and punction removed\n",
    "spam_test_features = [(build_bag_of_words_features(x), 'spam') for x in test_spam['text']]\n",
    "\n",
    "print(spam_test_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ham_test_features + spam_test_features\n",
    "\n",
    "print('num features for test: ', len(test))\n",
    "\n",
    "nltk.classify.util.accuracy(sent_classifier, test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_classifier.show_most_informative_features(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-brighton",
   "metadata": {},
   "source": [
    "**Observations**:  When displaying `100` of the top informative features, **most** of these are `spam:ham` ratios, meaning that the weight of the effect of these words ends up predicting a `spam` message.  In the most weighted case, the word `award` is `221` times more probable of being a spam message.  The word `home` is the highest weighted ham word with a `23:1` mulitiple of being not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_ref = []\n",
    "test_ref = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "    gold_ref.append(sent_classifier.classify(test[i][0]))\n",
    "    test_ref.append(test[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(gold_ref, test_ref)\n",
    "print(cm.pretty_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.pretty_format(show_percents=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-hayes",
   "metadata": {},
   "source": [
    "**Note:**  From the confusion matrix from `NLTK` there are `5.1%` or `57` of the values miscategorized as ham when they are really spam.  This is a baseline to compare with for later models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-tampa",
   "metadata": {},
   "source": [
    "### Test with Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training vocabulary\n",
    "train_vocab = set()\n",
    "\n",
    "for t in train:\n",
    "    vocabDict = t[0]\n",
    "    for key in vocabDict.keys():\n",
    "      train_vocab.add(key)\n",
    "len(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "docs=[\"txt us at 8787 for a free trip to hawaii!\", \n",
    "      \"I'm looking forward to when my day is over and I can go home\",\n",
    "      \"Nah I don't think he goes to usf\",\n",
    "      \"Your award for a free week of mobile service\"]\n",
    "\n",
    "for doc in docs:\n",
    "     t_features = {word: (word in word_tokenize(doc.lower())) for word in train_vocab}\n",
    "     print(doc,\" : \", sent_classifier.classify(t_features)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-reducing",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "With the NLTK model, the accuracy on the `test` partition of the data was about `~94%`.  When testing our sample strings it ended up classifying them correctly.  It's very possible to make just minor word changes and have these mis-classify, however this does show the model working properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-chemical",
   "metadata": {},
   "source": [
    "# Scikit Learn Naive Bayes Classification\n",
    "\n",
    "The following section will look to classify the data based on Scikit-Learn's `NaiveBayesClassification`, using both `ComplimentNB` and and `MultinomialNB` algorithms.  A number of options through different versions of the same process\n",
    "\n",
    "1. **Four total passes**\n",
    "    - The first two will use an imbalanced dataset\n",
    "    - The second two will use a balanced training set\n",
    "1. **For each of the two passes, different word vectorization will be used.**\n",
    "    - `CountVectorizer` which uses a sparse matrix of token counts per document\n",
    "    - `TfidfVectorizer` Tf-idf instead of the token counts, scales down the impact of tokens that occur very frequently in a given corpus and that are hence less informative than features that occur in a small fraction of the training corpus.\n",
    "1. **Hyper Parameter Tuning**\n",
    "    - Each of the passes will use a Grid Search Cross Validation to pick the best performing `alpha` setting.  This is tuned per training data set, and per word vectorization model from step 2.\n",
    "1. **Algorithms**\n",
    "    - See below.\n",
    "\n",
    "**Algorithms**\n",
    "\n",
    ">**ComplementNB** implements the complement naive Bayes (CNB) algorithm. CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets. CNB regularly outperforms MNB (often by a considerable margin) on text classification tasks.\n",
    "\n",
    "And next, after oversampling the minority class, try the Multinomial Naive Bayes Classifier.\n",
    "\n",
    ">**MultinomialNB** implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). \n",
    "\n",
    "\n",
    "**Metrics**    \n",
    "After everything is run, we can see which model performed the best.  The metric for determining the best model is `percision` primarily, since it will measure how precise/accurate the model is out of those predicted positive, how many of them are actual positive.\n",
    "\n",
    ">**Precision** is a good measure to determine, when the costs of False Positive is high. For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model[3].\n",
    "\n",
    "**Note:** Different than the NLTK version above, we will not do any special pre-processing but rather let `scikit-learn` do stop word removal and accent removal.  Because of this, we'll start with the raw imported CSV.\n",
    "\n",
    "**References:**  \n",
    " 1. [Detecting Fake News with Scikit-Learn](https://www.datacamp.com/community/tutorials/scikit-learn-fake-news)  \n",
    " 1. [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18)\n",
    " 1. [Accuracy, Precision, Recall or F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)\n",
    " 1. [ComplimentNB on Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html#sklearn.naive_bayes.ComplementNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "general-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "# Set `y` \n",
    "y = df.label\n",
    "X = df['text']\n",
    "\n",
    "# Drop the `label` column\n",
    "df.drop(\"label\", axis=1)\n",
    "\n",
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rough-commitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3733,)\n",
      "(3733,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-bronze",
   "metadata": {},
   "source": [
    "## Models on Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recognized-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer1 = CountVectorizer(stop_words='english', strip_accents='unicode')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train1 = count_vectorizer1.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test1 = count_vectorizer1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "corrected-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer1 = TfidfVectorizer(stop_words='english', max_df=0.7, strip_accents='unicode') \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train1 = tfidf_vectorizer1.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test1 = tfidf_vectorizer1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "banned-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yuo', 'yuou', 'yup', 'yupz', 'zebra', 'zed', 'zeros', 'zhong', 'zoe', 'zogtorius']\n",
      "['00', '000', '008704050406', '0089', '01223585236', '01223585334', '0125698789', '02', '0207', '02072069400']\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names of `tfidf_vectorizer` \n",
    "print(tfidf_vectorizer1.get_feature_names()[-10:])\n",
    "\n",
    "# Get the feature names of `count_vectorizer` \n",
    "print(count_vectorizer1.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "purple-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>yuo</th>\n",
       "      <th>yuou</th>\n",
       "      <th>yup</th>\n",
       "      <th>yupz</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3733 rows × 6744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  008704050406  0089  01223585236  01223585334  0125698789  02  \\\n",
       "0      0    0             0     0            0            0           0   0   \n",
       "1      0    0             0     0            0            0           0   0   \n",
       "2      0    0             0     0            0            0           0   0   \n",
       "3      0    0             0     0            0            0           0   0   \n",
       "4      0    0             0     0            0            0           0   0   \n",
       "...   ..  ...           ...   ...          ...          ...         ...  ..   \n",
       "3728   0    0             0     0            0            0           0   0   \n",
       "3729   0    0             0     0            0            0           0   0   \n",
       "3730   0    0             0     0            0            0           0   0   \n",
       "3731   0    0             0     0            0            0           0   0   \n",
       "3732   0    0             0     0            0            0           0   0   \n",
       "\n",
       "      0207  02072069400  ...  yuo  yuou  yup  yupz  zebra  zed  zeros  zhong  \\\n",
       "0        0            0  ...    0     0    0     0      0    0      0      0   \n",
       "1        0            0  ...    0     0    0     0      0    0      0      0   \n",
       "2        0            0  ...    0     0    0     0      0    0      0      0   \n",
       "3        0            0  ...    0     0    0     0      0    0      0      0   \n",
       "4        0            0  ...    0     0    0     0      0    0      0      0   \n",
       "...    ...          ...  ...  ...   ...  ...   ...    ...  ...    ...    ...   \n",
       "3728     0            0  ...    0     0    0     0      0    0      0      0   \n",
       "3729     0            0  ...    0     0    0     0      0    0      0      0   \n",
       "3730     0            0  ...    0     0    0     0      0    0      0      0   \n",
       "3731     0            0  ...    0     0    1     0      0    0      0      0   \n",
       "3732     0            0  ...    0     0    0     0      0    0      0      0   \n",
       "\n",
       "      zoe  zogtorius  \n",
       "0       0          0  \n",
       "1       0          0  \n",
       "2       0          0  \n",
       "3       0          0  \n",
       "4       0          0  \n",
       "...   ...        ...  \n",
       "3728    0          0  \n",
       "3729    0          0  \n",
       "3730    0          0  \n",
       "3731    0          0  \n",
       "3732    0          0  \n",
       "\n",
       "[3733 rows x 6744 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(count_train1.A, columns=count_vectorizer1.get_feature_names())\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "legitimate-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>yuo</th>\n",
       "      <th>yuou</th>\n",
       "      <th>yup</th>\n",
       "      <th>yupz</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3733 rows × 6744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  008704050406  0089  01223585236  01223585334  0125698789   02  \\\n",
       "0     0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "1     0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "2     0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "3     0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "4     0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "...   ...  ...           ...   ...          ...          ...         ...  ...   \n",
       "3728  0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "3729  0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "3730  0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "3731  0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "3732  0.0  0.0           0.0   0.0          0.0          0.0         0.0  0.0   \n",
       "\n",
       "      0207  02072069400  ...  yuo  yuou       yup  yupz  zebra  zed  zeros  \\\n",
       "0      0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "1      0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "2      0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "3      0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "4      0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "...    ...          ...  ...  ...   ...       ...   ...    ...  ...    ...   \n",
       "3728   0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "3729   0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "3730   0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "3731   0.0          0.0  ...  0.0   0.0  0.266889   0.0    0.0  0.0    0.0   \n",
       "3732   0.0          0.0  ...  0.0   0.0  0.000000   0.0    0.0  0.0    0.0   \n",
       "\n",
       "      zhong  zoe  zogtorius  \n",
       "0       0.0  0.0        0.0  \n",
       "1       0.0  0.0        0.0  \n",
       "2       0.0  0.0        0.0  \n",
       "3       0.0  0.0        0.0  \n",
       "4       0.0  0.0        0.0  \n",
       "...     ...  ...        ...  \n",
       "3728    0.0  0.0        0.0  \n",
       "3729    0.0  0.0        0.0  \n",
       "3730    0.0  0.0        0.0  \n",
       "3731    0.0  0.0        0.0  \n",
       "3732    0.0  0.0        0.0  \n",
       "\n",
       "[3733 rows x 6744 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_train1.A, columns=tfidf_vectorizer1.get_feature_names())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "authorized-asthma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-democrat",
   "metadata": {},
   "source": [
    "**Note:** The empty `set` denotes that the features (columns) are identical between the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-reflection",
   "metadata": {},
   "source": [
    "### Function for Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conscious-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-coral",
   "metadata": {},
   "source": [
    "### Function for Hyper Parameter Tuning\n",
    "\n",
    "GridSearch Cross Validation of `alpha` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "color-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(X, y, model):\n",
    "    vals = np.linspace(.0001, 2, 100)\n",
    "\n",
    "    parameters = {'alpha':vals}\n",
    "    model = model\n",
    "    clf = GridSearchCV(model, parameters)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # extract the best alpha score\n",
    "    return clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "distinguished-patch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alph_dict = get_alpha(count_train1, y_train, ComplementNB())\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "raising-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ComplementNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eastern-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.987     0.979     0.983      1602\n",
      "        spam      0.865     0.916     0.889       237\n",
      "\n",
      "    accuracy                          0.971      1839\n",
      "   macro avg      0.926     0.947     0.936      1839\n",
      "weighted avg      0.972     0.971     0.971      1839\n",
      "\n",
      "accuracy:   0.971\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm4ElEQVR4nO3dfZwVZf3/8debRfEGSA1BBAxNFJFERZE0b1ITyhsoMyE1TL5S5q8sv2WSlvZNytTKLM3QSpIS0UzwXkK7wRAFxBBQRFG5WQQkTQ1pgc/vj5m107Y3Z5cznNmz72ePeeyZa66Z+Ywbn73ONddco4jAzMxKq125AzAzq0ROrmZmGXByNTPLgJOrmVkGnFzNzDLg5GpmlgEnV2uUpO0l3SPpDUl3bMFxzpD0cCljKxdJR0p6rtxxWL7J41wrg6RPAxcCfYE3gXnAuIiYsYXHPQv4InB4RGzc0jjzTlIAfSJiSbljsdbNLdcKIOlC4Frgu0A3YA/gBmBYCQ7/PmBxW0isxZDUvtwxWCsREV5a8QK8B3gLOK2ROh1Iku/KdLkW6JBuOwZYDvwvsBqoBj6bbvs28C+gJj3HaOByYGLBsXsDAbRP188GXiRpPS8Fzigon1Gw3+HAk8Ab6c/DC7b9EfgO8Fh6nIeBLg1cW238FxXEPxz4GLAYWAd8o6D+IGAm8Hpa96fAtum2P6fX8nZ6vacXHP/rwCrg1tqydJ/3p+c4OF3fHVgLHFPu/294Ke/ilmvr90FgO+D3jdS5BBgMHAgMIEkwlxZs340kSfcgSaDXS9o5Ii4jaQ3fHhEdI+IXjQUiaUfgOuCjEdGJJIHOq6feLsB9ad33Aj8E7pP03oJqnwY+C3QFtgW+2sipdyP5b9AD+BZwE3AmMBA4EviWpL3SupuArwBdSP7bHQd8ASAijkrrDEiv9/aC4+9C0oofU3jiiHiBJPH+RtIOwK+AWyLij43Ea22Ak2vr915gbTT+tf0M4P8iYnVErCFpkZ5VsL0m3V4TEfeTtNr2bWE8m4H+kraPiOqIWFBPnROB5yPi1ojYGBG3Ac8CJxfU+VVELI6I9cBkkj8MDakh6V+uASaRJM4fR8Sb6fkXAAcARMSciHg8Pe9LwM+Bo4u4pssiYkMaz3+IiJuA54FZQHeSP2bWxjm5tn6vAV2a6AvcHXi5YP3ltOzdY9RJzv8EOjY3kIh4m+Sr9OeBakn3SepbRDy1MfUoWF/VjHhei4hN6efa5Pdqwfb1tftL2kfSvZJWSfoHScu8SyPHBlgTEe80UecmoD/wk4jY0ERdawOcXFu/mcA7JP2MDVlJ8pW21h5pWUu8DexQsL5b4caIeCgiPkLSgnuWJOk0FU9tTCtaGFNz/Iwkrj4R0Rn4BqAm9ml0SI2kjiT92L8ALk+7PayNc3Jt5SLiDZJ+xuslDZe0g6RtJH1U0lVptduASyXtKqlLWn9iC085DzhK0h6S3gOMrd0gqZukU9K+1w0k3Qub6jnG/cA+kj4tqb2k04F+wL0tjKk5OgH/AN5KW9Xn1dn+KrDXf+3VuB8DcyLif0j6km/c4iit1XNyrQAR8UOSMa6XAmuAZcD/A+5Oq1wBzAb+BswH5qZlLTnXNOD29Fhz+M+E2I5k1MFKkjvoR5PeLKpzjNeAk9K6r5Hc6T8pIta2JKZm+irJzbI3SVrVt9fZfjkwQdLrkj7V1MEkDQOGknSFQPJ7OFjSGSWL2FolP0RgZpYBt1zNzDLg5GpmlgEnVzOzDDi5mplloKInodjlvV2iR689yh2GNcO2Vf5739rMnTtnbUTsWqrjVXV+X8TG/3oQrl6xfs1DETG0VOcupYpOrj167cGUaY+VOwxrht133r7cIVgzbb+N6j5tt0Vi43o67NvkKDgA3pl3fVNP15VNRSdXM2uNBGr932CcXM0sXwS0qyp3FFvMydXM8kdNTfeQf06uZpYz7hYwM8uGW65mZiUm3HI1Mys9ueVqZpYJjxYwMys139AyMys94W4BM7NMuOVqZlZq7hYwMys9AVW+oWVmVnruczUzKzV3C5iZZcMtVzOzDLjlamZWYvLjr2Zm2aiAx19bf9vbzCpMekOrmKWpI0m/lLRa0jP1bPuqpJDUpaBsrKQlkp6TNKSgfKCk+em266Smm9ZOrmaWP7VdA00tTbsF+K+3w0rqBXwEeKWgrB8wAtg/3ecGSbVN6J8BY4A+6dLkG2edXM0sX2rncy1ByzUi/gysq2fTj4CLgCgoGwZMiogNEbEUWAIMktQd6BwRMyMigF8Dw5s6t/tczSxnmjXOtYuk2QXr4yNifKNHl04BVkTE03W+3fcAHi9YX56W1aSf65Y3ysnVzPKn+BtaayPikGIrS9oBuAQ4ob7N9ZRFI+WNcnI1s/zJbijW+4E9gdpWa09grqRBJC3SXgV1ewIr0/Ke9ZQ3yn2uZpYvKt1ogboiYn5EdI2I3hHRmyRxHhwRq4CpwAhJHSTtSXLj6omIqAbelDQ4HSXwGWBKU+dycjWz/CnRaAFJtwEzgX0lLZc0uqG6EbEAmAwsBB4Ezo+ITenm84CbSW5yvQA80NS53S1gZrlTxDDSokTEyCa2966zPg4YV0+92UD/5pzbydXMciV5y4sffzUzKy0JtXNyNTMrObdczcwy4ORqZpYBJ1czs1IT9T8T1co4uZpZrgi55WpmloV27Vr/801OrmaWO265mpmVmvtczcyy4ZarmVmJ+YaWmVlG/PirmVmpyd0CZmaZcHI1M8uAk6uZWYlVyg2t1v8YRAVauWI5n/74UE444iCGHjmQX42/HoD7p97F0CMHsne3HfnbvDnv1p9y5yRO+vBh7y57d9uRhfOfLlf4bd6yZcsYcvyHOfAD+3HwgP356XU/BmDdunWcOPQj9N+vDycO/Qh///vfyxxpjqnIJcecXHOoffsqvvHt7/HwY09x5wN/ZOIvf87zzy1in779uOFXtzHogx/6j/rDPjmCex+dxb2PzuIH1/+Cnr3eR78PDChT9Na+fXuuvOoHzJu/iD/NeJyf33g9ixYu5JqrruSYY4/jmUXPc8yxx3HNVVeWO9R8UvL4azFLnuU7ujaqa7fu9D/gIAA6duzE3vvsy6vVK9l7n77stfc+je57z+8nc9InTtsaYVoDunfvzkEHHwxAp06d6Nt3P1auXMG990zhzLNGAXDmWaO4Z+rdZYwy3yQVtRRxnF9KWi3pmYKyqyU9K+lvkn4vaaeCbWMlLZH0nKQhBeUDJc1Pt12nIk7u5Jpzy195mQXzn2bAwEOLqn/f3b/j5I9/KuOorFgvv/QS8+Y9xaGDDmP1q6/SvXt3IEnAa1avLnN0OVa6boFbgKF1yqYB/SPiAGAxMBZAUj9gBLB/us8NkqrSfX4GjCF53Xafeo75X5xcc+ztt97iC+eM5JvfuYpOnTo3WX/enCfYbocd2He//bdCdNaUt956i5GfOpWrf3AtnTs3/fuzfytVyzUi/gysq1P2cERsTFcfB3qmn4cBkyJiQ0QsJXmN9iBJ3YHOETEzIgL4NTC8qXM7ueZUTU0N55/zaYadOoIhJw0vap97776Tkz/uLoE8qKmpYeSnTuX0kWcw/OOfAKBrt25UV1cDUF1dza5du5YzxNwqNrGmybWLpNkFy5hmnu4c4IH0cw9gWcG25WlZj/Rz3fJGZZZcJe0o6T5JT0t6RtLpkl6S9H1JT6TL3mndkyXNkvSUpD9I6paWXy5pgqSH030/IemqtO/jQUnbZBV/OUUEF3/5PN6/z76MPu9LRe2zefNmHph6FycNd3Itt4jg8+eOZt+++3HBVy58t/zEk05h4q0TAJh46wROOnlYuULMvWbc0FobEYcULOOLPYekS4CNwG9qi+qpFo2UN34NxQbSAkOBlRExICL6Aw+m5f+IiEHAT4Fr07IZwOCIOAiYBFxUcJz3AyeSNNknAo9GxAeA9Wl5xZkzayZ33/FbZv7lT+8Or3r0Dw/y0H1TOGLA3jw1exb/8+lTOftTp7y7zxMzZ7Db7j3Yo/eeZYzcAP762GP89je38qdHH+GwgQdy2MADefCB+/nqRRfzyB+m0X+/Pjzyh2l89aKLyx1qfmU8FEvSKOAk4Iz0qz4kLdJeBdV6AivT8p71lDcqy4cI5gPXSPo+cG9E/CVtxt+Wbr8N+FH6uSdwe9q3sS2wtOA4D0REjaT5QBX/TtLzgd51T5p+LRgDsHvPXnU3twqHDD6cF1b/s95tQ06sv7Uz+Iij+N0Df8oyLCvSER/6EOtr6m/YPPDw9K0cTeuU5UMEkoYCXweOjojCf2hTgd9K+iGwO8mNqyciYpOkNyUNBmYBnwF+0tR5Mmu5RsRiYCBJEvyepG/Vbiqslv78CfDTtEX6OWC7gjob0uNtBmoK/spspp4/DhExvvYrwi7v7VKy6zGzrUQlHYp1GzAT2FfSckmjSb41dwKmSZon6UaAiFgATAYWkjTizo+ITemhzgNuJrnJ9QL/7qdtUGYtV0m7A+siYqKkt4Cz002nA1emP2emZe8BVqSfR2UVk5nln4BSNVwjYmQ9xb9opP44YFw95bOB/s05d5bdAh8Arpa0Gaghyfx3Ah0kzSJpNdde+OXAHZJWkAyNcMehWZtVGXMLZJZcI+Ih4KHCsvQ/2PUR8e06dacAU+o5xuV11js2tM3MKkc7T5ZtZlZiKl23QDlt1eQaEb235vnMrPURbrmamWXCLVczswz4hpaZWYlJ7hYwM8uAh2KZmWWiAnKrk6uZ5Y9brmZmpeZxrmZmpZfMLdD6s6uTq5nljkcLmJlloAIark6uZpYzcreAmVnJlXI+13JycjWznPFDBGZmmaiA3OrkamY5UyFzC2T5am0zs2arHedaohcU/lLSaknPFJTtImmapOfTnzsXbBsraYmk5yQNKSgfKGl+uu06FXFyJ1czy51SJVfgFmBonbKLgekR0QeYnq4jqR8wAtg/3ecGSVXpPj8DxpC8brtPPcf8L06uZpY7UnFLUyLiz8C6OsXDgAnp5wnA8ILySRGxISKWkrxGe5Ck7kDniJgZEQH8umCfBrnP1cxypxmjBbpIml2wPj4ixjexT7eIqAaIiGpJXdPyHiRvn661PC2rST/XLW+Uk6uZ5Yqk5tzQWhsRh5Tq1PWURSPljXK3gJnlTqm6BRrwavpVn/Tn6rR8OdCroF5PYGVa3rOe8kY5uZpZ7rSTilpaaCowKv08CphSUD5CUgdJe5LcuHoi7UJ4U9LgdJTAZwr2aZC7Bcwsd0r1EIGk24BjSPpmlwOXAVcCkyWNBl4BTgOIiAWSJgMLgY3A+RGxKT3UeSQjD7YHHkiXRjm5mlmuqIQTt0TEyAY2HddA/XHAuHrKZwP9m3NuJ1czy50KeECr4eQq6Sc0ckcsIr6USURm1uZVwuOvjbVcZzeyzcwsEwJU7+in1qXB5BoREwrXJe0YEW9nH5KZtXUV0HBteiiWpA9KWggsStcHSLoh88jMrG0qcl6BvM/5Wsw412uBIcBrABHxNHBUhjGZWRuX8UMEW0VRowUiYlmdvxKbGqprZrYlBFRVQL9AMcl1maTDgZC0LfAl0i4CM7Ms5P0rfzGK6Rb4PHA+ySwwK4AD03Uzs5Irtksg7/m3yZZrRKwFztgKsZiZAWzJvAG5Ucxogb0k3SNpTfq6hCmS9toawZlZ26Qilzwrplvgt8BkoDuwO3AHcFuWQZlZ29ZWhmIpIm6NiI3pMpEiJoo1M2sJSVS1K27Js8bmFtgl/fiopIuBSSRJ9XTgvq0Qm5m1UTlvlBalsRtac/jPVxx8rmBbAN/JKigza9vy/pW/GI3NLbDn1gzEzAyS1lzOv/EXpagntCT1B/oB29WWRcSvswrKzNq2im651pJ0GclrEvoB9wMfBWaQvLvbzKykJKiqgORazGiBT5K8EmFVRHwWGAB0yDQqM2vTKuEJrWKS6/qI2AxslNSZ5DW0fojAzDJTynGukr4iaYGkZyTdJmk7SbtImibp+fTnzgX1x0paIuk5SUNaeg3FJNfZknYCbiIZQTAXeKKlJzQza0qpWq6SepBMNnVIRPQHqoARwMXA9IjoA0xP15HUL92+PzAUuEFSVUuuoZi5Bb6QfrxR0oNA54j4W0tOZmbWFKFSzy3QHtheUg2wA7ASGEtyLwlgAvBH4OvAMGBSRGwAlkpaAgwCZrbkpPWSdHBj2yJibnNPtrVtU9WO3d6zXdMVLTd2PvT/lTsEK7fm9ad2kVT4vr/xETG+diUiVki6BngFWA88HBEPS+oWEdVpnWpJXdNdegCPFxxveVrWbI21XH/QyLYAjm3JCc3MmtKM0QJrI+KQhjamfanDgD2B14E7JJ3ZyPHqO3GLHvdv7CGCD7fkgGZmW0KUdJzr8cDSiFhDcty7gMOBVyV1T1ut3Ulu1EPSUu1VsH9Pkm6EZivmhpaZ2VbVTsUtRXgFGCxpByUZ+ziSN6lMBUaldUYBU9LPU4ERkjpI2hPoQwtv4Bf1hJaZ2dZUqsdfI2KWpDtJRjltBJ4CxgMdgcmSRpMk4NPS+gskTQYWpvXPj4gWvTPQydXMciUZZlW60QIRcRlwWZ3iDSSt2PrqjwPGbel5i3kTgSSdKelb6foekgZt6YnNzBpSwm6Bsimmz/UG4IPAyHT9TeD6zCIyszat9tXaFTtZdoHDIuJgSU8BRMTf01dsm5llohLutBeTXGvSx78CQNKuwOZMozKzNi3vk7IUo5jkeh3we6CrpHEks2RdmmlUZtZmSSV//LUsiplb4DeS5pDcWRMwPCIWZR6ZmbVZFZBbi5osew/gn8A9hWUR8UqWgZlZ2ySgfc5vVhWjmG6B+/j3iwq3I3lG9zmSKbnMzEquTbRcI+IDhevpbFmfa6C6mdmWaQVjWIvR7Ce0ImKupEOzCMbMDJI5XVu7YvpcLyxYbQccDKzJLCIza9Pa0qu1OxV83kjSB/u7bMIxM2sDyTV9eKBjRHxtK8VjZm1c7eOvrV1jr3lpHxEbG3vdi5lZybWC12YXo7GW6xMk/avzJE0F7gDert0YEXdlHJuZtVFt4gktYBfgNZJ3ZtWOdw3AydXMSq4t3NDqmo4UeIZ/J9VaLXphl5lZMSqg4dpocq0ieRVCyd6GaGbWFKHmvP01txpLrtUR8X9bLRIzM6iYJ7Qam5O2Ai7PzFqjdum0g00txZC0k6Q7JT0raZGkD0raRdI0Sc+nP3cuqD9W0hJJz0ka0uJraGRbvS/vMjPLkqh9SWHTS5F+DDwYEX2BASSv1r4YmB4RfYDp6TqS+gEjSCamGgrckI73b7YGk2tErGvJAc3MtlSpWq6SOgNHAb8AiIh/RcTrwDBgQlptAjA8/TwMmBQRGyJiKbAEaNELWSvhVTVmVmGa0XLtIml2wTKmzqH2IpkL5VeSnpJ0s6QdgW4RUQ2Q/uya1u8BLCvYf3la1mzNnhXLzCxLEs0ZLbA2Ig5pZHt7koehvhgRsyT9mLQLoKHT11PWotFRbrmaWe6oyKUIy4HlETErXb+TJNm+Kqk7QPpzdUH9XgX79wRWtuQanFzNLFeSJ7RK0+caEauAZZL2TYuOAxYCU4FRadkoYEr6eSowQlIHSXsCfUimAmg2dwuYWe6UeBzoF4HfSNoWeBH4LEnDcrKk0cArwGkAEbFA0mSSBLwROD8iNrXkpE6uZpY7pXxAKyLmAfX1y9Y73DQixgHjtvS8Tq5mlitt4fFXM7OykJOrmVnptf7U6uRqZnkjt1zNzEpOVMYYUSdXM8sdt1zNzDJQCfO5OrmaWa4k3QKtP7s6uZpZ7lRAr4CTq5nljZBbrmZmpeeWq5lZibnP1cwsC4J2FTDQ1cnVzHLHfa6WuXfeeYcTjjuaDRs2sGnjRoZ/4lQu/da3391+7Q+v4ZKxF/HyitV06dKljJG2PTdedgYfPao/a9a9ySGnfReASz73Mc75xOGs+ftbAFz206k8NGMhAP377M5PLx1Jpx23Y/Pm4ENnXsWGf23kU0MH8rVzhhARVK95g3MuncBrr79dtusqt2Sy7HJHseWcXHOuQ4cO3P/QdDp27EhNTQ3Hf/hIThjyUQYdNpjly5bxyPQ/0GuPPcodZpt06z2Pc+Ptf+Lm73zmP8p/MvFRrr11+n+UVVW145dXjGL0N3/N/MUr2OU9O1KzcRNVVe24+muf5OBTr+C1199m3AXD+PzpRzPu5/dvzUvJnUpouVZAz0Zlk0THjh0BqKmpoaam5t1HA7/+tQu54nvfr4hHBVujx+a+wLo3/llU3eM/2Jdnnl/B/MUrAFj3xtts3hzvvsV0x+23BaBTx+2pXvNGZjG3Fs14+2tuObm2Aps2bWLwoQfRu2c3jj3ueA4ddBj33TOV7rvvzgEHDCh3eFbH50ccxRO3j+XGy85gp07bA9Bnj65EwNTrz+evv/06F446HoCNGzdzwXdv58nJ3+DFh8ex3167ccvdfy1n+GUnkre/FrPk2VZNrpJ6S3pma56zElRVVfH4k0+x+MVlzJn9JPPn/42rvv9dvnnZ/5U7NKvjpjv+Qr+TL+ewEVeyau0/uPLCTwDQvqqKww/ai89ecgvHnfNDTjl2AMcM2of27dtx7iePZPDI77PXCZfwzOIVfO2cE8p8FeWmov+XZ265tiI77bQTRx51NPfdM4WXXlrK4EMPZL999mTF8uUcMXggq1atKneIbd7qdW+yeXMQEfzyrsc4pP/7AFix+nX+MmcJr73+NuvfqeHBGQs4qG8vBuzTE4Cly9cCcOe0uQwesFfZ4s+FIrsEim24SqqS9JSke9P1XSRNk/R8+nPngrpjJS2R9JykIVtyGeVIrlWSbpK0QNLDkraXdK6kJyU9Lel3knYAkHSLpJ9JelTSi5KOlvRLSYsk3VKG2Le6NWvW8PrrrwOwfv16Hn1kOgMGHMTLy19l0eKlLFq8lB49e/LY43PYbbfdyhussVuXzu9+HnbsABa+UA3AtL8upH+fHmy/3TZUVbXjyIF7s+jFVaxc8wZ999qNLjsn/erHDe7Lc0v9R1JFLkW6AFhUsH4xMD0i+gDT03Uk9QNGAPsDQ4EbJFW19BrKMVqgDzAyIs5NX2F7KnBXRNwEIOkKYDTwk7T+zsCxwCnAPcARwP8AT0o6MH2z47skjQHGABVxF33VqmrGjD6bTZs2sXnzZk795Gl89MSTyh2WARO+dzZHDuxDl506suTB7/CdG+/nqIF9OGDfnkQEL1ev44tX3AbA62+u57qJjzBj4kVEBA/NWMCDMxYA8N3xDzDt5i9Ts3ETr1SvY8xlE8t5WWWXDMUqzVd+ST2BE0ne5nphWjwMOCb9PAH4I/D1tHxSRGwAlkpaAgwCZrbk3OVIrksLEuIcoDfQP02qOwEdgYcK6t8TESFpPvBqRMwHkLQg3XdeQV0iYjwwHuDggYdEVhextXzgAwcw84m5jdZZtHjpVorGCo0ae8t/lU24u+F/h5Puf5JJ9z/5X+U33zmDm++cUcrQWr1mpNYukmYXrI9Pc0Cta4GLgE4FZd0iohogIqoldU3LewCPF9Rbnpa1SDmS64aCz5uA7YFbgOER8bSks/n3X5XC+pvr7LsZj9M1q0jNGF64NiIOaeAYJwGrI2KOpGOKOW09ZS1uoOUlOXUCqiVtA5wBrChzPGZWRiXqFTgCOEXSx4DtgM6SJgKvSuqetlq7A6vT+suBXgX79wRWtvTkeRkt8E1gFjANeLbMsZhZmZXihlZEjI2InhHRm+RG1SMRcSYwFRiVVhsFTEk/TwVGSOogaU+S+0NPtPQatmrLNSJeAvoXrF9TsPln9dQ/u5F9z65b38wqRLZDWK8EJksaDbwCnAYQEQvSm+wLgY3A+RGxqaUnyUu3gJkZUNsqLW12jYg/kowKICJeA45roN44kpEFW8zJ1czyRZ4Vy8wsG06uZmallv95A4rh5GpmuZPzCa+K4uRqZrnSzHkDcsvJ1czypwKyq5OrmeVOqSZuKScnVzPLndafWp1czSxvKqTT1cnVzHLHQ7HMzEpMeCiWmVkmnFzNzDLgbgEzswy45WpmloEKyK1OrmaWQxWQXZ1czSxXspgsuxycXM0sXzxZtplZRioguebl7a9mZikV/b8mjyT1kvSopEWSFki6IC3fRdI0Sc+nP3cu2GespCWSnpM0pKVX4eRqZrkjFbcUYSPwvxGxHzAYOF9SP+BiYHpE9AGmp+uk20YA+wNDgRskVbXkGpxczSxX1IylKRFRHRFz089vAouAHsAwYEJabQIwPP08DJgUERsiYimwBBjUkutwcjWz/Ck+u3aRNLtgGdPgIaXewEHALKBbRFRDkoCBrmm1HsCygt2Wp2XN5htaZpY7zZgse21EHNJUJUkdgd8BX46If6jh49e3IYoNppBbrmaWO6XqFgCQtA1JYv1NRNyVFr8qqXu6vTuwOi1fDvQq2L0nsLIl1+Dkamb5UuTNrGIat0qaqL8AFkXEDws2TQVGpZ9HAVMKykdI6iBpT6AP8ERLLsPdAmaWQyUb6HoEcBYwX9K8tOwbwJXAZEmjgVeA0wAiYoGkycBCkpEG50fEppac2MnVzHKllJNlR8QMGs7UxzWwzzhg3Jae28nVzHLHj7+amWXAE7eYmWWh9edWJ1czy58KyK1OrmaWL82YNyDXnFzNLHfc52pmlgG3XM3MMuDkamZWcsVNhJ13Tq5mliulfEKrnDxxi5lZBtxyNbPcacZ8rrnl5Gpm+eJxrmZmpdecibDzzMnVzPKnArKrk6uZ5Y6HYpmZZcB9rmZmGXByNTPLQCV0CyiiRa/kbhUkrQFeLnccGekCrC13EFa0Sv59vS8idi3VwSQ9SPLfqxhrI2Joqc5dShWdXCuZpNkRcUi547Di+PfV9vjxVzOzDDi5mpllwMm19Rpf7gCsWfz7amPc52pmlgG3XM3MMuDkamaWASdXM7MMOLmamWXAydXMLANOrmZbiVQJ05FYsTwUq0JIOh74GDAFeDYiXi1zSNYASSOAPsAk4JWI2FDmkCwDbrlWAEkDgO+S/D5HA2dJel95o7JahS1WSacD/wvsAVwNfExSp3LFZtlxcm3lJO1G0gq6JiK+TNIa6g6cJmnPcsZmSWKN9OuhpK5AR+CMiDgXeBg4BThOUucyhmkZcLdAKyZpKHADsApoHxGDCspPAZYBP4qId8oXZdtVJ7FeAJxH0qCZERHnpOWfBz4C/Aq4L/wPsmK45dpKSeoLfBb4OHAMsJ2kSQAR8SBwL3C3E2v5FCTWI4DDgGOB04F9JF2R1rkRuB+Y68RaWdxybWXS/rudgG+R/GMdExGz0m1PAKsj4qTyRWi10t/V3sBPgM3AWRHxmqR+JN84noqIr5QzRsuOW66tTCT+DtwEzACGSDog3TYI2EPSwR72Ux6F/93T39XzwI+Bd4ATJL03IhYCXwT2k7Srf1eVyS3XVkTSCcCHgaXA3cDOwOeAdcC9ETGvbMFZ3T7WzwC7Ac+SfO0fApxB0l3zcESslbRtRPyrbAFbptxybSUknQR8D5gHnAT8HFgPXA/sDgyX1FGSf6dlUpBYvwycA7xOMuzqCuBR4NfASODDkto5sVY2/0NsBSTtDAwFTiNJqLsBi0kS63rgR8DtEfFWRGwuW6BtVOEfNEn7AAOA44HOgIAdgctIEuyPgb/691T53C3QCqT/eHcl6Qa4FRgBBDAVqAZO9qiA8kvHFb8KdCX5NnElyU3HM4GvA7+PiG+UL0LbmtqXOwBrmKSjSB4I+FdE/F7SdiSPtr4g6TBgOnCTE2t5SDoc2CMiJkn6InABSev0ryQt1hkRsVFSDXAfcF35orWtzck1pyQdCtxMcuPqcEmnR8QISb0lTSRpEZ0TEc+UM842bmfge+mY454kN62OJRl+tT3wZUm7puUfiYhVZYvUtjp3C+SQpCNJ+lcfiIgH0rKZwIMkXzUPBtZ7dED5SfoI8EPg8Yg4V1IHkt/drsCewJ+BJyLilTKGaWXgG1o5I2kv4FRgFEkLqNZZQJ+I2BARM51Y8yEipgGXAsMkjUhnuLoN+AfJELlHnFjbJncL5IikU4DLgROBhcBXJP0FeBp4H8mg812Av/tRyfyIiCmSNpJ0EZD2wf4K6BgR/yh3fFYe7hbICUkHArcAIyNiUVo2kWRYzwygCrg/Iu4uU4jWBEkfBcYDX4mIO8sdj5WXk2tOSNqPZLjOTKAbyWQsK0harL2Az0fEQ5KqImJT2QK1RqV9sC9ExIvljsXKy8k1JyR1BM4meYLnByQPCRwFPA/0BcYCJ3h0gFnr4OSaM7XPm0s6hORxyfMj4tF0HOX9EfFCmUM0syI4ueaMpCrgQJIp6b4bEVPKG5GZtYSTaw5J2hHoGhFLa6ej8+gAs9bFydXMLAN+iMDMLANOrmZmGXByNTPLgJOrmVkGnFytZCQdI+ne9PMpki5upO5Okr7QgnNcLumrxZbXqXOLpE8241y9JfmhDWsRJ1drUjr2tlkiYmpEXNlIlZ2AZidXs9bCybUNS1tmz0qaIOlvku6UtEO67SVJ35I0AzhN0gmSZkqaK+mO9HFdJA1NjzED+ETBsc+W9NP0czdJv5f0dLocTjIv7fslzZN0dVrva5KeTGP5dsGxLpH0nKQ/APsWcV3npsd5WtLvaq8pdbykv0hanL70EUlVkq4uOPfntvS/rZmTq+0LjI+IA0jmIC1sTb4TER8C/kAyZ+nxEXEwMBu4MH3tzE3AycCRJC9OrM91wJ8iYgDJRN8LgItJJjg5MCK+lr42vA8wiOQJtYGSjpI0kOSdYQeRJO9Di7imuyLi0PR8i4DRBdt6A0eTTOt4Y3oNo4E3IuLQ9Pjnpu/DMmsxz+dqyyLisfTzROBLwDXp+u3pz8FAP+Cx9IGxbUlm7+oLLI2I5+HdKRLH1HOOY4HPAKQzer2RvtG20Anp8lS63pEk2XYiebHfP9NzTC3imvpLuoKk66Ej8FDBtsnpm1efl/Rieg0nAAcU9Me+Jz334iLOZVYvJ1er+4he4frb6U8B0yJiZGHFdA7aUj3iJ+B7EfHzOuf4cgvOcQswPCKelnQ2yfSNteq7XgFfjIjCJIyk3s08r9m73C1ge0j6YPp5JMnE3HU9DhwhaW8ASTtI2gd4FthT0vsL9q/PdOC8dN8qSZ2BN0lapbUeAs4p6MvtIakryTuoPi5pe0mdSLogmtIJqJa0DXBGnW2nSWqXxrwX8Fx67vPS+kjaJ53fwazFnFxtETBK0t+AXYCf1a0QEWtI5pq9La33ONA3faX3GOC+9IbWyw2c4wLgw5LmA3OA/SPiNZJuhmckXR0RDwO/BWam9e4EOkXEXJLuiXnA74C/FHFN3wRmAdNI/gAUeg74E/AAyQTk75C8ZXchMDcdevVz/K3OtpAnbmnD0q+990ZE/3LHYlZp3HI1M8uAW65mZhlwy9XMLANOrmZmGXByNTPLgJOrmVkGnFzNzDLw/wHQemkxCbl0zAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf1.fit(count_train1, y_train)\n",
    "y_pred = clf1.predict(count_test1)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "included-surgeon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alph_dict = get_alpha(tfidf_train1, y_train, ComplementNB())\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "limiting-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = ComplementNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "moving-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham      0.988     0.976     0.982      1602\n",
      "        spam      0.848     0.920     0.883       237\n",
      "\n",
      "    accuracy                          0.968      1839\n",
      "   macro avg      0.918     0.948     0.932      1839\n",
      "weighted avg      0.970     0.968     0.969      1839\n",
      "\n",
      "accuracy:   0.968\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf2.fit(tfidf_train1, y_train)\n",
    "y_pred = clf2.predict(tfidf_test1)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-buffer",
   "metadata": {},
   "source": [
    "## Oversample the Minority Class\n",
    "Oversampling can be defined as adding more copies of the minority class. Oversampling can be a good choice when you don’t have a ton of data to work with.  \n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class.\n",
    "\n",
    "https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html?highlight=resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "ham = X[X.label == 'ham']\n",
    "spam = X[X.label == 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "spam_upsampled = resample(spam,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(ham), # match number in majority class\n",
    "                          random_state=27) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([ham, spam_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new class counts\n",
    "upsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-bracket",
   "metadata": {},
   "source": [
    "**Note:** Now we can see that the number of `spam` and `ham` entries are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-better",
   "metadata": {},
   "source": [
    "## Post Oversampling Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced dataset\n",
    "y_train = upsampled.label\n",
    "X_train = upsampled.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english', strip_accents='unicode')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode') \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph_dict = get_alpha(count_train, y_train, MultinomialNB())\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(count_train, y_train)\n",
    "y_pred = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph_dict = get_alpha(tfidf_train, y_train, MultinomialNB())\n",
    "alph = alph_dict['alpha']\n",
    "alph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-depression",
   "metadata": {},
   "source": [
    "**Note**: The very low `alpha` value returned suggest that our model might be overfit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=alph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(tfidf_train, y_train)\n",
    "y_pred = clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=['spam', 'ham'])\n",
    "plot_confusion_matrix(cm, classes=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-stylus",
   "metadata": {},
   "source": [
    "## Test with Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"txt us at 8787 for a free trip to hawaii!\", \n",
    "           \"I'm looking forward to when my day is over and I can go home\",\n",
    "           \"Nah I don't think he goes to usf\",\n",
    "           \"Your award for a free week of mobile service\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    sample_trans = tfidf_vectorizer.transform([sample])\n",
    "    print(sample, \"=\", clf.predict(sample_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-homework",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-grant",
   "metadata": {},
   "source": [
    "# Clustering with Kmeans\n",
    "\n",
    "It's possible to apply the same methods of vecorization, specifically `TF-IDF` and use an unsupervised model such as `kMeans` to build a number of clusters representing different groupings of like data.  Since we know there are naturally `2` clusters in here, we can try to run the algorithm with the `spam` and `ham` label removed.  \n",
    "\n",
    "After the model is built, we can try our sample strings against the clusters seeing if they are placed logically in the right ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "X = df['text']\n",
    "\n",
    "# Drop the `label` column\n",
    "df.drop(\"label\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode')\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train k-means model\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=1000, n_init=1, random_state=999)\n",
    "model.fit(X)\n",
    "\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions:\")\n",
    "samples = [\"txt us at 8787 for a free trip to hawaii!\", \n",
    "           \"I'm looking forward to when my day is over and I can go home\",\n",
    "           \"Nah I don't think he goes to usf\",\n",
    "           \"Your award for a free week of mobile service\"]\n",
    "\n",
    "# prediction\n",
    "pred = model.predict(vectorizer.transform(samples))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-capacity",
   "metadata": {},
   "source": [
    "**kMeans Notes:**  \n",
    "\n",
    "The kMeans clustering unsupervised algorithm with two clusters comes up with an approimation of a `spam` and a `ham` cluster.  feeding in the same items from our prior tests result in the same predictions.  `#1` and `#4` predicted as `spam`, and `#2` and `#3` as `ham`.\n",
    "\n",
    "While you wouldn't use an unsupervised method when you have actual labels, it demonstrates really well how clustering, an unsupervised method, can be used on text.  It is also very useful when you have some subject matter on the text, where we know there are generally `2` labels we're looking for."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
