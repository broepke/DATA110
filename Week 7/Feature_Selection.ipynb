{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlimited-noise",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-with-categorical-data/\n",
    "\n",
    "Tutorial Overview\n",
    "\n",
    "This tutorial is divided into three parts; they are:\n",
    "\n",
    "1. Breast Cancer Categorical Dataset\n",
    "    - Categorical Feature Selection\n",
    "    - Chi-Squared Feature Selection\n",
    "2. Mutual Information Feature Selection\n",
    "3. Modeling With Selected Features\n",
    "    - Model Built Using All Features\n",
    "    - Model Built Using Chi-Squared Features\n",
    "    - Model Built Using Mutual Information Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subjective-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nearby-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data = pd.read_csv(filename, header=None)\n",
    "    # retrieve numpy array\n",
    "    dataset = data.values\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    # format all fields as string\n",
    "    X = X.astype(str)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bigger-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = load_dataset('breast-cancer.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civic-cooper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (191, 9) (191,)\n",
      "Test (95, 9) (95,)\n"
     ]
    }
   ],
   "source": [
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-cream",
   "metadata": {},
   "source": [
    "Now that we are familiar with the dataset, let’s look at how we can encode it for modeling.\n",
    "\n",
    "We can use the OrdinalEncoder() from scikit-learn to encode each variable to integers. This is a flexible class and does allow the order of the categories to be specified as arguments if any such order is known.\n",
    "\n",
    "Note: I will leave it as an exercise to you to update the example below to try specifying the order for those variables that have a natural ordering and see if it has an impact on model performance.\n",
    "\n",
    "The best practice when encoding variables is to fit the encoding on the training dataset, then apply it to the train and test datasets.\n",
    "\n",
    "The function below named prepare_inputs() takes the input data for the train and test sets and encodes it using an ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cooked-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-afternoon",
   "metadata": {},
   "source": [
    "We also need to prepare the target variable.\n",
    "\n",
    "It is a binary classification problem, so we need to map the two class labels to 0 and 1. This is a type of ordinal encoding, and scikit-learn provides the LabelEncoder class specifically designed for this purpose. We could just as easily use the OrdinalEncoder and achieve the same result, although the LabelEncoder is designed for encoding a single variable.\n",
    "\n",
    "The prepare_targets() function integer encodes the output data for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conservative-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-asbestos",
   "metadata": {},
   "source": [
    "We can call these functions to prepare our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latin-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-minnesota",
   "metadata": {},
   "source": [
    "## Categorical Feature Selection\n",
    "\n",
    "There are two popular feature selection techniques that can be used for categorical input data and a categorical (class) target variable.\n",
    "\n",
    " - Chi-Squared Statistic.\n",
    " - Mutual Information Statistic.\n",
    "\n",
    "## Chi-Squared Feature Selection\n",
    "\n",
    "Pearson’s chi-squared statistical hypothesis test is an example of a test for independence between categorical variables.\n",
    "\n",
    "The scikit-learn machine library provides an implementation of the chi-squared test in the chi2() function. This function can be used in a feature selection strategy, such as selecting the top k most relevant features (largest values) via the SelectKBest class.\n",
    "\n",
    "For example, we can define the SelectKBest class to use the chi2() function and select all features, then transform the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "painful-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "neutral-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.472553\n",
      "Feature 1: 0.029193\n",
      "Feature 2: 2.137658\n",
      "Feature 3: 29.381059\n",
      "Feature 4: 8.222601\n",
      "Feature 5: 8.100183\n",
      "Feature 6: 1.273822\n",
      "Feature 7: 0.950682\n",
      "Feature 8: 3.699989\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-assist",
   "metadata": {},
   "source": [
    "In this case, we can see the scores are small and it is hard to get an idea from the number alone as to which features are more relevant.\n",
    "\n",
    "Perhaps features 3, 4, 5, and 8 are most relevant.\n",
    "\n",
    "This clearly shows that feature 3 might be the most relevant (according to chi-squared) and that perhaps four of the nine input features are the most relevant.\n",
    "\n",
    "We could set k=4 When configuring the SelectKBest to select these top four features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-mentor",
   "metadata": {},
   "source": [
    "## Mutual Information Feature Selection\n",
    "\n",
    "Mutual information from the field of information theory is the application of information gain (typically used in the construction of decision trees) to feature selection.\n",
    "\n",
    "Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\n",
    "\n",
    "The scikit-learn machine learning library provides an implementation of mutual information for feature selection via the mutual_info_classif() function.\n",
    "\n",
    "Like chi2(), it can be used in the SelectKBest feature selection strategy (and other strategies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demographic-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "functioning-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.000000\n",
      "Feature 1: 0.000000\n",
      "Feature 2: 0.077700\n",
      "Feature 3: 0.057197\n",
      "Feature 4: 0.011755\n",
      "Feature 5: 0.062190\n",
      "Feature 6: 0.000000\n",
      "Feature 7: 0.045384\n",
      "Feature 8: 0.008443\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-football",
   "metadata": {},
   "source": [
    "A bar chart of the feature importance scores for each input feature is created.\n",
    "\n",
    "Importantly, a different mixture of features is promoted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-avenue",
   "metadata": {},
   "source": [
    "Now that we know how to perform feature selection on categorical data for a classification predictive modeling problem, we can try developing a model using the selected features and compare the results.\n",
    "\n",
    "## Modeling With Selected Features\n",
    "\n",
    "There are many different techniques for scoring features and selecting features based on scores; how do you know which one to use?\n",
    "\n",
    "A robust approach is to evaluate models using different feature selection methods (and numbers of features) and select the method that results in a model with the best performance.\n",
    "\n",
    "In this section, we will evaluate a Logistic Regression model with all features compared to a model built from features selected by chi-squared and those features selected via mutual information.\n",
    "\n",
    "Logistic regression is a good model for testing feature selection methods as it can perform better if irrelevant features are removed from the model.\n",
    "\n",
    "## Model Built Using All Features\n",
    "\n",
    "As a first step, we will evaluate a LogisticRegression model using all the available features.\n",
    "\n",
    "The model is fit on the training dataset and evaluated on the test dataset.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "turkish-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_enc, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_enc)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-martial",
   "metadata": {},
   "source": [
    "## Model Built Using Chi-Squared Features\n",
    "\n",
    "We can use the chi-squared test to score the features and select the four most relevant features.\n",
    "\n",
    "The select_features() function below is updated to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "second-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "geological-warning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.74\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fs, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-match",
   "metadata": {},
   "source": [
    "In this case, we see that the model achieved an accuracy of about 74%, a slight drop in performance.\n",
    "\n",
    "It is possible that some of the features removed are, in fact, adding value directly or in concert with the selected features.\n",
    "\n",
    "At this stage, we would probably prefer to use all of the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-bubble",
   "metadata": {},
   "source": [
    "## Model Built Using Mutual Information Features\n",
    "\n",
    "We can repeat the experiment and select the top four features using a mutual information statistic.\n",
    "\n",
    "The updated version of the select_features() function to achieve this is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elect-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "impossible-proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fs, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
