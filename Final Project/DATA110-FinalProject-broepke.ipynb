{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bulgarian-player",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "**DATA110: Intro to Machine Learning**  \n",
    "Brian Roepke  \n",
    "April 24th, 2021  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-prompt",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "analysis objective and the ML approach applied as well as why you selected it.\n",
    "\n",
    "\n",
    "Yelp has opened up a large portion of its dataset for academic and personal use. It contains a massive amount of textual data from their reviews and other information about their businesses. I propose to build an NLP model building a sentiment analysis and mapping the polarity to the rating given for the review. Additionally, a machine learning model will predict the highest-rated business by location, the number of reviews, and categories assigned. Finally, I will attempt to use TensorFlow to create a Neural Network. While we only loosely covered this in class, I will try to combine the Machine Learning methods we learned with the tutorials from class to build a classification model off of the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-found",
   "metadata": {},
   "source": [
    "# EDA/DATA PREP\n",
    "\n",
    "explore data issues that may require cleansing, data wrangling/munging, etc..  Include visualizations, statistical analysis, etc.. to better understand the data such as how it's distributed and correlations. You must include analysis/text that explains the meaning of each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# NLTK Imports and Downloads\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yelp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63bff0-46b8-4aa0-a756-a1e44c756646",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd1c65-c8d6-4e5a-8dfe-0e217a0d7676",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "Nulll values are generally not desireable in a dataset.  In certain cases, observations (rows) with low counts will simply be dropped, in other cases, they can be filled with other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NULL values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace235c-cc2a-4b9c-bf1b-edfe2b0f5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_open'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ca401-357f-452b-ab63-d70da7edbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['is_open'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2802297-91e6-49e2-897b-7ca3f47544e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop is_open column\n",
    "# df.drop(columns=['is_open'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f490d-51b8-4df9-8cb3-7eb3fd1979d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column 'text_len' that counts the length for the derived field\n",
    "df['text_len'] = df.apply(lambda row: len(row['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287af029-c9c1-4da6-8b16-f0b0080350aa",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "A common practice is to review any duplicates.  If there are large quantities, they can skew the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db001354-60e5-4cec-a5e7-5d2858d74a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_before = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "len_after = df.shape[0]\n",
    "\n",
    "print(\"Before =\", len_before)\n",
    "# drop duplicates\n",
    "print(\"After =\", len_after)\n",
    "print('')\n",
    "print(\"Total Removed =\", len_before - len_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7292d3-88ac-4f6c-9baf-860e6ed6df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get categorical data\n",
    "cat_data = df.select_dtypes(include=['object'])\n",
    "cat_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e0cef-0e33-4417-a3f7-68ac79fd9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show counts values of each categorical variable\n",
    "print (df['city'].value_counts(), '\\n')\n",
    "print (df['state'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5b93f-51b2-4f4d-9a8c-98768301d9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5e115-9e84-4e80-a392-82aea861fa74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fff71fa-992f-4385-8cff-ef643883a56c",
   "metadata": {},
   "source": [
    "**Notes:**  \n",
    "1. **stars_x:** float, star rating, rounded to half-stars\n",
    "1. **stars_y:** integer, star rating (the data is a float64 here, but only valid numbers were integers 1-5)\n",
    "\n",
    "`\n",
    "    // integer, number of useful votes received\n",
    "    \"useful\": 0,\n",
    "\n",
    "    // integer, number of funny votes received\n",
    "    \"funny\": 0,\n",
    "\n",
    "    // integer, number of cool votes received\n",
    "    \"cool\": 0\n",
    "    \n",
    "    \n",
    "    {\n",
    "    // string, 22 character unique string business id\n",
    "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
    "\n",
    "    // string, the business's name\n",
    "    \"name\": \"Garaje\",\n",
    "\n",
    "    // string, the full address of the business\n",
    "    \"address\": \"475 3rd St\",\n",
    "\n",
    "    // string, the city\n",
    "    \"city\": \"San Francisco\",\n",
    "\n",
    "    // string, 2 character state code, if applicable\n",
    "    \"state\": \"CA\",\n",
    "\n",
    "    // string, the postal code\n",
    "    \"postal code\": \"94107\",\n",
    "\n",
    "    // float, latitude\n",
    "    \"latitude\": 37.7817529521,\n",
    "\n",
    "    // float, longitude\n",
    "    \"longitude\": -122.39612197,\n",
    "\n",
    "    // float, star rating, rounded to half-stars\n",
    "    \"stars\": 4.5,\n",
    "\n",
    "    // integer, number of reviews\n",
    "    \"review_count\": 1198,\n",
    "\n",
    "    // integer, 0 or 1 for closed or open, respectively\n",
    "    \"is_open\": 1,\n",
    "\n",
    "    // object, business attributes to values. note: some attribute values might be objects\n",
    "    \"attributes\": {\n",
    "        \"RestaurantsTakeOut\": true,\n",
    "        \"BusinessParking\": {\n",
    "            \"garage\": false,\n",
    "            \"street\": true,\n",
    "            \"validated\": false,\n",
    "            \"lot\": false,\n",
    "            \"valet\": false\n",
    "        },\n",
    "    },\n",
    "\n",
    "    // an array of strings of business categories\n",
    "    \"categories\": [\n",
    "        \"Mexican\",\n",
    "        \"Burgers\",\n",
    "        \"Gastropubs\"\n",
    "    ],\n",
    "\n",
    "    // an object of key day to value hours, hours are using a 24hr clock\n",
    "    \"hours\": {\n",
    "        \"Monday\": \"10:00-21:00\",\n",
    "        \"Tuesday\": \"10:00-21:00\",\n",
    "        \"Friday\": \"10:00-21:00\",\n",
    "        \"Wednesday\": \"10:00-21:00\",\n",
    "        \"Thursday\": \"10:00-21:00\",\n",
    "        \"Sunday\": \"11:00-18:00\",\n",
    "        \"Saturday\": \"10:00-21:00\"\n",
    "    }\n",
    "}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b832b2f-f6bf-4a1e-8c20-ef6672371f60",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=df, x='state', palette='tab20c');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=df, x=\"stars_x\", palette='tab20c');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(15,10), kind='density', subplots=True, layout=(4,3), sharex=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26425335-fe56-478e-b403-ebb475fb2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(x='review_count', data=df, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac6117-9ac2-4ace-9856-0537033688b9",
   "metadata": {},
   "source": [
    "### Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74f929-dc87-46bd-821f-3854b076df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the number of outliers in a column.\n",
    "def get_outliers(df):\n",
    "    '''Function to identify the number of outliers +/- 3 standard deviations outside of mean.\n",
    "    Pass this function a dataframe and it returns a dictionary'''\n",
    "    \n",
    "    outs = {}\n",
    "    \n",
    "    df = df.select_dtypes(include=['int64'])\n",
    "\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        # calculate summary statistics\n",
    "        data_mean, data_std = np.mean(df[col]), np.std(df[col])\n",
    "        \n",
    "        # identify outliers\n",
    "        cut_off = data_std * 3\n",
    "        lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "        \n",
    "        # identify outliers\n",
    "        outliers = [x for x in df[col] if x < lower or x > upper]\n",
    "        \n",
    "        outs[col] = len(outliers)\n",
    "        \n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6786fa-b607-43a7-acd4-1f4c00b4ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd6a2b-1d0f-4787-946c-0e56ddc3010d",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "For **Parts** of our analysis, the text needs to have some basic transformation for our models to work propertly.  These are as follows:\n",
    "\n",
    "1. **Lower**: Convert all characters to lowercase\n",
    "1. **Remove Punctuation**: In most cases, punctuation doesn't help NLP and ML models and can be removed.\n",
    "1. **Stop Word Removal**: Stop words generally don't add context to analysis (unless the length of text is very short (`100` - `200` characters) and can be removed.\n",
    "1. **Lemmatization**: Words will be reduced to there *Lemma* or root.  This will greatly improve the accuracy of the analysis since words like `simming` and `swimmer` will be reduced to `swim`.\n",
    "\n",
    "**Note**: The orginal text will be preserved for other analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18826dfc-1821-422f-9b57-a2643fb5932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade0cdf-da58-4886-b59a-15d19448378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text, stem=\"None\"):\n",
    "    \n",
    "    final_string = \"\"\n",
    "    \n",
    "    # Make lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "    useless_words = useless_words + ['.', ',', '!', \"'\"]\n",
    "    \n",
    "    # Remove stop words\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "    \n",
    "    # Remove numbers\n",
    "    text_filtered = [re.sub('\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "    \n",
    "    # Stem or Lemmatize\n",
    "    if stem == 'Stem':\n",
    "        stemmer = PorterStemmer() \n",
    "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "    elif stem == 'Lem':\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "    else:\n",
    "        text_stemmed = text_filtered\n",
    "    \n",
    "    for word in text_stemmed:\n",
    "        final_string += word + \" \"\n",
    "    \n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9678ea8-061a-4b0e-a6e4-a20b64cc05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(lambda x: clean_string(x, stem='Lem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b9917-2f1f-4a6e-92c2-7bb6f954b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197139ac-9eac-4035-982d-644f256d6708",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "For our sentiment analysis section, we will be using the `TextBlob` package to assist in creating `polarity scores` or sentiment scores that range from `-1` to `1` where lower scores are more negative and higher more positive.  Based off of these scores, we'll add a classifier of `1` for positive and `0` for negative to be used later in our prediction model. \n",
    "\n",
    "**Note**: `0` is technically nuetral sentiment, we'll verify how many observations were neutral before assuming we can use a binary label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603ae57-07b1-4e79-bb1f-c34c2de9b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(x):\n",
    "    '''using TextBlob, get the sentiment score for a given body of text'''\n",
    "    blob = TextBlob(x)\n",
    "    return blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6870b-5069-4e1e-b389-4ab9732fb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Polarity Scoring from TextBlob\n",
    "df['sentiment'] = df['text'].apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed26ef-432d-45b7-bf82-31fd30e36743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a few extra columns to aid in the analysis\n",
    "df['sentiment_label'] = df['sentiment'].apply(lambda x: 1 if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387c90e-e46e-4197-b7ef-a42c3cafe710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[-3:]].sample(5, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686625c-a05c-4649-83d5-6f4f870f62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df, x='sentiment', palette=\"tab20c\", bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b5f13-149b-4ac0-9869-a54cdd55aabc",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "The distributions of sentiment, similar to the `1-5` star reviews is left skewed to the positive.  There are very few that have a `<0` polartity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8095abf-7f4f-43d3-8990-c8de46e4dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['sentiment'] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-recorder",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION/ MODELING \n",
    "\n",
    "determine features to be applied and create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59573a-1407-4b51-8fe6-8ace8c95a56e",
   "metadata": {},
   "source": [
    "## Sentiment Based Prediction Model:\n",
    "\n",
    "Next, we'll create a Supervised ML model to predict whether a customer will recommend a product based on the text from the review and the sentiment of that text, and the length of the review.\n",
    "\n",
    "To create our model, we will be mixing both text and numeric values.  There are multiple ways to accomplish this, but we will be using a `ColumnTransformer` in a Pipeline[2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a4e11c-7f5c-41de-a0f9-b586c9410cac",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "During this section, we will use the ColumnTransformer to perform all of the pre-processing steps.  A `FeatureUnion` could also be used but isn't required since we're not transforming the entire numeric data with a PCA process [2].\n",
    "\n",
    ">*FeatureUnion applies different transformers to the whole of the input data and then combines the results by concatenating them.*  \n",
    ">*ColumnTransformer, on the other hand, applies different transformers to different subsets of the whole input data, and again concatenates the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab63bb7-47a7-468b-bba3-d8b139ad121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['categories', 'city', 'state', 'text', 'sentiment', 'text_len']]\n",
    "y = df['is_open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3edbd-7726-437f-a1c1-d2a3f447a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0d328-fbf6-4888-9fec-ac4369b75015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipe(clf):\n",
    "    '''Create a pipeline for a given classifier.  The classifier needs to be an instance\n",
    "    of the classifier with all parmeters needed specified.'''\n",
    "    \n",
    "    # Each pipeline uses the same column transformer.  \n",
    "    column_trans = ColumnTransformer(\n",
    "        [('Text', TfidfVectorizer(stop_words='english'), 'text'),\n",
    "         ('Categories', TfidfVectorizer(stop_words='english'), 'categories'),\n",
    "         ('city', OneHotEncoder(dtype='int', handle_unknown = 'ignore'), ['city']),\n",
    "         ('state', OneHotEncoder(dtype='int', handle_unknown = 'ignore'), ['state']),\n",
    "         ('Text Length', MinMaxScaler(), ['text_len']),\n",
    "         ('Sentiment', MinMaxScaler(), ['sentiment'])],\n",
    "        remainder='drop') \n",
    "    \n",
    "    pipeline = Pipeline([('prep',column_trans),\n",
    "                         ('over', SMOTE(random_state=42)),\n",
    "                         ('under', RandomUnderSampler(random_state=42)),\n",
    "                         ('clf', clf)])\n",
    "     \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371e8a7-6d36-4289-b2b0-383d73acb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'ComplementNB' : ComplementNB(),\n",
    "          #'SVC' : SVC(class_weight='balanced', random_state=42),\n",
    "          #'RandomForest' : RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "          'LogReg' : LogisticRegression(random_state=42, class_weight='balanced', max_iter=500)}\n",
    "\n",
    "for name, model, in models.items():\n",
    "    clf = model\n",
    "    pipeline = create_pipe(clf)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='f1_macro', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    print(name, ': Mean f1 Macro: %.3f and Standard Deviation: (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-nancy",
   "metadata": {},
   "source": [
    "# PERFORMANCE ASSESSMENT\n",
    "\n",
    "assess model performance using appropriate metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd34d1-573e-46a6-a63c-3f3405870c21",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637616b-c96f-456b-a2bd-f333853f3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf25c34-5d6b-4f6f-8357-0087cc6993b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4da2c-03a0-47b7-96df-6e2ce2417e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(parameters, X, y, pipeline):\n",
    "    ''' implements a the GridSearch Cross validation for a given model and set of parameters'''\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(pipeline, parameters, scoring='f1_macro', n_jobs=-1, cv=cv, error_score='raise')\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a29d9-346e-4e64-b01e-93e4d2fa1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'clf__solver' : ['newton-cg', 'lbfgs', 'sag', 'liblinear'],\n",
    "               'clf__C' : [.1, 1, 10 ,100]}]\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "pipeline = create_pipe(clf)\n",
    "grid = get_params(parameters, X_train, y_train, pipeline)\n",
    "\n",
    "print(\"Best cross-validation accuracy: {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set score: {:.3f}\".format(grid.score(X_test, y_test))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "log_C = grid.best_params_['clf__C']\n",
    "log_solver = grid.best_params_['clf__solver']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8809cb-b07d-4b79-8e2a-e7574f0e9dc1",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec320ec-a566-4ede-b43e-151288ad3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf8287-7705-470e-a948-3142d8249107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_print(pipeline, name):\n",
    "    ''' take a supplied pipeline and run it against the train-test spit \n",
    "    and product scoring results.'''\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    plot_confusion_matrix(cm, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a69a2-ec3c-4352-bc9b-60f6bc210d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=log_C, solver=log_solver, random_state=42, max_iter=500)\n",
    "pipeline = create_pipe(clf)\n",
    "fit_and_print(pipeline, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645979f5-6b77-46f2-aca5-a970a7aa4694",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "This model performed extremely well across our dataset with an `f1 macro` score of `0.915`.  The dataset has imbalanced, which was corrected for SMOTE (Over Sampling combined with Undersampling).  The result was a very strong predictor model based on `text`, `sentiment`, and `text_len`.\n",
    "\n",
    "**Synthetic Minority Oversampling Technique** uses a nearest-neighbor approach for generating new minority class samples.  The method is applied only to the training data and then tested on the original, untouched test partition.  The method chosen here is first to oversample the minority class making it balanced, and then undersample it to reduce the size.  This helps bring balance without bloating the dataset [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-actress",
   "metadata": {},
   "source": [
    "# CONCLUSION \n",
    "\n",
    "a conclusion summarizing the analysis and the results. Were you able to meet your analysis objective as described in your introduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-daily",
   "metadata": {},
   "source": [
    "# REFERENCES\n",
    "\n",
    "1. [Yelp Reviews Dataset](https://www.yelp.com/dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-custody",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
